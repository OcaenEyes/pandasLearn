{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 回归\n",
    "- 线性分类\n",
    "- 逻辑回归的正则化\n",
    "- 逻辑回归的优缺点\n",
    "- 验证和学习曲线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 最小二乘法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性回归，首先指定一个模型将因变量 $y$ 和特征联系起来，对线性模型而言，依赖函数的形式如下：\n",
    "$$y = w_0 + \\sum_{i=1}^m w_i x_i$$ \n",
    "如果为每项观测加上一个虚维度 $x_0 = 1$（比如偏置），那么就可以把 $w_0$ 整合进求和项中，改写为一个略微紧凑的形式：\n",
    "$$y = \\sum_{i=0}^m w_i x_i = \\textbf{w}^\\text{T} \\textbf{x}$$\n",
    "如果有一个特征观测矩阵，其中矩阵的行是数据集中的观测，那么需要在左边加上一列。由此，线性模型可以定义为：\n",
    "$$ \\textbf y = \\textbf X \\textbf w + \\epsilon$$\n",
    "\n",
    "其中：\n",
    "- $\\textbf y \\in \\mathbb{R}^n$：因变量（目标变量）。\n",
    "- $w$：模型的参数向量（在机器学习中，这些参数经常被称为权重）。\n",
    "- $\\textbf X$：观测及其特征矩阵，大小为 n 行、m+1 列（包括左侧的虚列），其秩的大小为 $\\text{rank}\\left(\\textbf X\\right) = m + 1 $。\n",
    "- $\\epsilon $：一个变量，用来表示随机、不可预测模型的错误。\n",
    "\n",
    "表达式亦可写成：\n",
    "$$ y_i = \\sum_{j=0}^m w_j X_{ij} + \\epsilon_i$$\n",
    "\n",
    "模型具有如下限制（否则它就不是线性回归了）：\n",
    "- 随机误差的期望为零：$\\forall i: \\mathbb{E}\\left[\\epsilon_i\\right] = 0 $;\n",
    "- 随机误差具有相同的有限方差，这一性质称为等分散性：$\\forall i: \\text{Var}\\left(\\epsilon_i\\right) = \\sigma^2 < \\infty $;\n",
    "- 随机误差不相关：$\\forall i \\neq j: \\text{Cov}\\left(\\epsilon_i, \\epsilon_j\\right) = 0 $.\n",
    "\n",
    "权重 $w_i$ 的估计 $\\widehat{w}_i$  满足如下条件时，称其为线性：\n",
    "$$ \\widehat{w}_i = \\omega_{1i}y_1 + \\omega_{2i}y_2 + \\cdots + \\omega_{ni}y_n$$\n",
    "\n",
    "其中对于 $\\forall\\ k\\ $，$\\omega_{ki}$ 仅依赖于 $X$ 中的样本。由于寻求最佳权重的解是一个线性估计，这一模型被称为线性回归。\n",
    "再引入一项定义：当期望值等于估计参数的真实值时，权重估计被称为无偏（unbiased）：\n",
    "$$ \\mathbb{E}\\left[\\widehat{w}_i\\right] = w_i$$\n",
    "\n",
    "计算这些权重的方法之一是普通最小二乘法（OLS）。OLS 可以最小化因变量实际值和模型给出的预测值之间的均方误差：\n",
    "$$ \\begin{array}{rcl}\\mathcal{L}\\left(\\textbf X, \\textbf{y}, \\textbf{w} \\right) &=& \\frac{1}{2n} \\sum_{i=1}^n \\left(y_i - \\textbf{w}^\\text{T} \\textbf{x}_i\\right)^2 \\\\\n",
    "&=& \\frac{1}{2n} \\left\\| \\textbf{y} - \\textbf X \\textbf{w} \\right\\|_2^2 \\\\\n",
    "&=& \\frac{1}{2n} \\left(\\textbf{y} - \\textbf X \\textbf{w}\\right)^\\text{T} \\left(\\textbf{y} - \\textbf X \\textbf{w}\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "为了解决这一优化问题，需要计算模型参数的导数。将导数设为零，然后求解关于 $\\textbf w$ 的等式，倘若不熟悉矩阵求导，可以参考下面的 4 个式子：\n",
    "$$\\begin{array}{rcl} \n",
    "\\frac{\\partial}{\\partial \\textbf{X}} \\textbf{X}^{\\text{T}} \\textbf{A} &=& \\textbf{A} \\end{array}$$\n",
    "\n",
    "$$\\begin{array}{rcl} \\frac{\\partial}{\\partial \\textbf{X}} \\textbf{X}^{\\text{T}} \\textbf{A} \\textbf{X} &=& \\left(\\textbf{A} + \\textbf{A}^{\\text{T}}\\right)\\textbf{X} \\end{array}$$\n",
    "\n",
    "$$\\begin{array}{rcl}\\frac{\\partial}{\\partial \\textbf{A}} \\textbf{X}^{\\text{T}} \\textbf{A} \\textbf{y} &=&  \\textbf{X}^{\\text{T}} \\textbf{y} \\end{array}$$\n",
    "\n",
    "$$\\begin{array}{rcl} \\frac{\\partial}{\\partial \\textbf{X}} \\textbf{A}^{-1} &=& -\\textbf{A}^{-1} \\frac{\\partial \\textbf{A}}{\\partial \\textbf{X}} \\textbf{A}^{-1} \n",
    "\\end{array}$$\n",
    "\n",
    "现在开始计算模型参数的导数：\n",
    "$$ \\begin{array}{rcl} \\frac{\\partial \\mathcal{L}}{\\partial \\textbf{w}} &=& \\frac{\\partial}{\\partial \\textbf{w}} \\frac{1}{2n} \\left( \\textbf{y}^{\\text{T}} \\textbf{y} -2\\textbf{y}^{\\text{T}} \\textbf{X} \\textbf{w} + \\textbf{w}^{\\text{T}} \\textbf{X}^{\\text{T}} \\textbf{X} \\textbf{w}\\right) \\\\\n",
    "&=& \\frac{1}{2n} \\left(-2 \\textbf{X}^{\\text{T}} \\textbf{y} + 2\\textbf{X}^{\\text{T}} \\textbf{X} \\textbf{w}\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "$$ \\begin{array}{rcl} \\frac{\\partial \\mathcal{L}}{\\partial \\textbf{w}} = 0 &\\Leftrightarrow& \\frac{1}{2n} \\left(-2 \\textbf{X}^{\\text{T}} \\textbf{y} + 2\\textbf{X}^{\\text{T}} \\textbf{X} \\textbf{w}\\right) = 0 \\\\\n",
    "&\\Leftrightarrow& -\\textbf{X}^{\\text{T}} \\textbf{y} + \\textbf{X}^{\\text{T}} \\textbf{X} \\textbf{w} = 0 \\\\\n",
    "&\\Leftrightarrow& \\textbf{X}^{\\text{T}} \\textbf{X} \\textbf{w} = \\textbf{X}^{\\text{T}} \\textbf{y} \\\\\n",
    "&\\Leftrightarrow& \\textbf{w} = \\left(\\textbf{X}^{\\text{T}} \\textbf{X}\\right)^{-1} \\textbf{X}^{\\text{T}} \\textbf{y}\n",
    "\\end{array}$$\n",
    "基于上述的定义和条件，可以说，根据高斯-马尔可夫定理，模型参数的 OLS 估计是所有线性无偏估计中最优的，即通过 OLS 估计可以获得最低的方差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 最大似然估计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最大似然估计是解决线性回归问题一种常用方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 偏置-方差分解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性回归预测的误差性质（可以推广到机器学习算法上）\n",
    "- 目标变量的真值 $y$ 是确定性函数 $f\\left(\\textbf{x}\\right)$ 和随机误差 $\\epsilon$ 之和：$y = f\\left(\\textbf{x}\\right) + \\epsilon$。\n",
    "- 误差符合均值为零、方差一致的正态分布：$\\epsilon \\sim \\mathcal{N}\\left(0, \\sigma^2\\right)$。\n",
    "- 目标变量的真值亦为正态分布：$y \\sim \\mathcal{N}\\left(f\\left(\\textbf{x}\\right), \\sigma^2\\right)$。\n",
    "- 试图使用一个协变量线性函数逼近一个未知的确定性函数 $f\\left(\\textbf{x}\\right)$，这一协变量线性函数是函数空间中估计函数 $f$ 的一点，即均值和方差的随机变量。\n",
    "\n",
    "因此，点 $\\textbf{x}$ 的误差可分解为：\n",
    "$$ \\begin{array}{rcl} \n",
    "\\text{Err}\\left(\\textbf{x}\\right) &=& \\mathbb{E}\\left[\\left(y - \\widehat{f}\\left(\\textbf{x}\\right)\\right)^2\\right] \\\\\n",
    "&=& \\mathbb{E}\\left[y^2\\right] + \\mathbb{E}\\left[\\left(\\widehat{f}\\left(\\textbf{x}\\right)\\right)^2\\right] - 2\\mathbb{E}\\left[y\\widehat{f}\\left(\\textbf{x}\\right)\\right] \\\\\n",
    "&=& \\mathbb{E}\\left[y^2\\right] + \\mathbb{E}\\left[\\widehat{f}^2\\right] - 2\\mathbb{E}\\left[y\\widehat{f}\\right] \\\\\n",
    "\\end{array}$$\n",
    "\n",
    "为了简洁，省略函数的参数，分别考虑每个变量。根据公式 $\\text{Var}\\left(z\\right) = \\mathbb{E}\\left[z^2\\right] - \\mathbb{E}\\left[z\\right]^2$ 可以分解前两项为：\n",
    "$$ \\begin{array}{rcl} \n",
    "\\mathbb{E}\\left[y^2\\right] &=& \\text{Var}\\left(y\\right) + \\mathbb{E}\\left[y\\right]^2 = \\sigma^2 + f^2\\\\\n",
    "\\mathbb{E}\\left[\\widehat{f}^2\\right] &=& \\text{Var}\\left(\\widehat{f}\\right) + \\mathbb{E}\\left[\\widehat{f}\\right]^2 \\\\\n",
    "\\end{array}$$\n",
    "\n",
    "注意：\n",
    "$$ \\begin{array}{rcl} \n",
    "\\text{Var}\\left(y\\right) &=& \\mathbb{E}\\left[\\left(y - \\mathbb{E}\\left[y\\right]\\right)^2\\right] \\\\\n",
    "&=& \\mathbb{E}\\left[\\left(y - f\\right)^2\\right] \\\\\n",
    "&=& \\mathbb{E}\\left[\\left(f + \\epsilon - f\\right)^2\\right] \\\\\n",
    "&=& \\mathbb{E}\\left[\\epsilon^2\\right] = \\sigma^2\n",
    "\\end{array}$$\n",
    "\n",
    "$$ \\mathbb{E}[y] = \\mathbb{E}[f + \\epsilon] = \\mathbb{E}[f] + \\mathbb{E}[\\epsilon] = f$$\n",
    "\n",
    "接着处理和的最后一项。由于误差和目标变量相互独立，所以可以将它们分离，写为：\n",
    "$$ \\begin{array}{rcl} \n",
    "\\mathbb{E}\\left[y\\widehat{f}\\right] &=& \\mathbb{E}\\left[\\left(f + \\epsilon\\right)\\widehat{f}\\right] \\\\\n",
    "&=& \\mathbb{E}\\left[f\\widehat{f}\\right] + \\mathbb{E}\\left[\\epsilon\\widehat{f}\\right] \\\\\n",
    "&=& f\\mathbb{E}\\left[\\widehat{f}\\right] + \\mathbb{E}\\left[\\epsilon\\right] \\mathbb{E}\\left[\\widehat{f}\\right]  = f\\mathbb{E}\\left[\\widehat{f}\\right]\n",
    "\\end{array}$$\n",
    "\n",
    "最后，将上述公式合并为：\n",
    "$$ \\begin{array}{rcl} \n",
    "\\text{Err}\\left(\\textbf{x}\\right) &=& \\mathbb{E}\\left[\\left(y - \\widehat{f}\\left(\\textbf{x}\\right)\\right)^2\\right] \\\\\n",
    "&=& \\sigma^2 + f^2 + \\text{Var}\\left(\\widehat{f}\\right) + \\mathbb{E}\\left[\\widehat{f}\\right]^2 - 2f\\mathbb{E}\\left[\\widehat{f}\\right] \\\\\n",
    "&=& \\left(f - \\mathbb{E}\\left[\\widehat{f}\\right]\\right)^2 + \\text{Var}\\left(\\widehat{f}\\right) + \\sigma^2 \\\\\n",
    "&=& \\text{Bias}\\left(\\widehat{f}\\right)^2 + \\text{Var}\\left(\\widehat{f}\\right) + \\sigma^2\n",
    "\\end{array}$$\n",
    "\n",
    "由此，从上等式可知，任何线性模型的预测误差由三部分组成：\n",
    "- 偏差（bias）: $\\text{Bias}\\left(\\widehat{f}\\right)$ 度量了学习算法的期望输出与真实结果的偏离程度, 刻画了算法的拟合能力，偏差偏高表示预测函数与真实结果差异很大。\n",
    "- 方差（variance）: $\\text{Var}\\left(\\widehat{f}\\right)$ 代表「同样大小的不同的训练数据集训练出的模型」与「这些模型的期望输出值」之间的差异。训练集变化导致性能变化，方差偏高表示模型很不稳定。\n",
    "- 不可消除的误差（irremovable error）: $\\sigma^2$ 刻画了当前任务任何算法所能达到的期望泛化误差的下界，即刻画了问题本身的难度。\n",
    "\n",
    "尽管无法消除 $\\sigma^2$，但我们可以影响前两项。理想情况下，希望同时消除偏差和方差（见下图中左上），但是在实践中，常常需要在偏置和不稳定（高方差）间寻找平衡。\n",
    "<img src=\"https://doc.shiyanlou.com/courses/uid214893-20190505-1557025218835\" width=\"400\">\n",
    "\n",
    "一般而言，当模型的计算量增加时（例如，自由参数的数量增加了），估计的方差（分散程度）也会增加，但偏置会下降，这可能会导致过拟合现象。另一方面，如果模型的计算量太少（例如，自由参数过低)，这可能会导致欠拟合现象。\n",
    "<img src=\"https://doc.shiyanlou.com/courses/uid214893-20190505-1557025236837\" width=\"480\">\n",
    "\n",
    "高斯-马尔可夫定理表明：在线性模型参数估计问题中，OLS 估计是最佳的线性无偏估计。这意味着，如果存在任何无偏线性模型 g，可以确信 $Var\\left(\\widehat{f}\\right) \\leq Var\\left(g\\right)$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 线性回归的正则化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "低偏置和低方差往往是不可兼得的，所以在一些情形下，会为了稳定性（降低模型的方差）而导致模型的偏置 $\\text{Var}\\left(\\widehat{f}\\right)$ 提高。高斯-马尔可夫定理成立的条件之一就是矩阵 $\\textbf{X}$ 是满秩的，否则 OLS 的解 $\\textbf{w} = \\left(\\textbf{X}^\\text{T} \\textbf{X}\\right)^{-1} \\textbf{X}^\\text{T} \\textbf{y}$ 就不存在，因为逆矩阵 $\\left(\\textbf{X}^\\text{T} \\textbf{X}\\right)^{-1}$ 不存在，此时矩阵 $\\textbf{X}^\\text{T} \\textbf{X}$ 被称为奇异矩阵或退化矩阵。这类问题被称为病态问题，必须加以矫正，也就是说，矩阵 $\\textbf{X}^\\text{T} \\textbf{X}$ 需要变成非奇异矩阵（这正是这一过程叫做正则化的原因）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们常常能在这类数据中观察到所谓的多重共线性：两个或更多特征高度相关，也就是矩阵 $\\textbf{X}$ 的列之间存在类似线性依赖的关系（又不完全是线性依赖）。例如，在「基于特征预测房价」这一问题中，属性「含阳台的面积」和「不含阳台的面积」会有一个接近线性依赖的关系。数学上，包含这类数据的矩阵 $\\textbf{X}^\\text{T} \\textbf{X}$ 被称为可逆矩阵，但由于多重共线性，一些本征值（特征值）会接近零。在 $\\textbf{X}^\\text{T} \\textbf{X}$ 的逆矩阵中，因为其本征值为 $\\frac{1}{\\lambda_i}$，所以有些本征值会变得特别大。本征值这种巨大的数值波动会导致模型参数估计的不稳定，即在训练数据中加入一组新的观测会导致完全不同的解。为了解决上述问题，有一种正则化的方法称为吉洪诺夫（Tikhonov）正则化，大致上是在均方误差中加上一个新变量："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\begin{array}{rcl} \\mathcal{L}\\left(\\textbf{X}, \\textbf{y}, \\textbf{w} \\right) &=& \\frac{1}{2n} \\left\\| \\textbf{y} - \\textbf{X} \\textbf{w} \\right\\|_2^2 + \\left\\| \\Gamma \\textbf{w}\\right\\|^2\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "吉洪诺夫矩阵常常表达为单位矩阵乘上一个系数：$\\Gamma = \\frac{\\lambda}{2} E$。在这一情形下，最小化均方误差问题变为一个 L2 正则化问题。若对新的损失函数求导，设所得函数为零，据  $\\textbf{w}$ 重整等式，便得到了这一问题的解："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\begin{array}{rcl} \n",
    "\\textbf{w} &=& \\left(\\textbf{X}^{\\text{T}} \\textbf{X} + \\lambda \\textbf{E}\\right)^{-1} \\textbf{X}^{\\text{T}} \\textbf{y}\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这类回归被称为岭回归（ridge regression）。岭为对角矩阵，在 $\\textbf{X}^\\text{T} \\textbf{X}$ 矩阵上加上这一对角矩阵，以确保能得到一个正则矩阵。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width='500px;' src=\"https://doc.shiyanlou.com/courses/uid214893-20190505-1557025255573\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 线性分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性分类器背后的基本思路是，目标分类的值可以被特征空间中的一个超平面分开。如果这可以无误差地达成，那么训练集被称为线性可分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面已经介绍了线性回归和普通最小二乘法（OLS）。现在考虑一个二元分类问题，将目标分类记为「+1」（正面样本）和「-1」（负面样本）。最简单的线性分类器可以通过回归定义：\n",
    "$$ a(\\textbf{x}) = \\text{sign}(\\textbf{w}^\\text{T}\\textbf x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中：\n",
    " - $\\textbf{x}$ 是特征向量（包括标识）。\n",
    " - $\\textbf{w}$ 是线性模型中的权重向量（偏置为 $w_0$）。\n",
    " - $\\text{sign}(\\bullet)$ 是符号函数，返回参数的符号。\n",
    " - $a(\\textbf{x})$ 是分类 $\\textbf{x}$ 的分类器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 基于逻辑回归的线性分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逻辑回归是线性分类器的一个特殊情形，但逻辑回归有一个额外的优点：它可以预测样本 $\\textbf{x}_\\text{i}$ 为分类「+」的概率 $p_+$：\n",
    "$$ p_+ = P\\left(y_i = 1 \\mid \\textbf{x}_\\text{i}, \\textbf{w}\\right) $$\n",
    "逻辑回归不仅能够预测样本是「+1」还是「-1」，还能预测其分别是「+1」和「-1」的概率是多少。对于很多业务问题（比如，信用评分问题）而言，这是一个非常重要的优点。下面是一个预测贷款违约概率的例子。\n",
    "\n",
    "<img width='300px;' src='https://doc.shiyanlou.com/courses/uid214893-20190505-1557025438757'>\n",
    "\n",
    "银行选择一个阈值 $p_*$ 以预测贷款违约的概率（上图中阈值为0.15），超过阈值就不批准贷款。\n",
    "为了预测概率 $p_+ \\in [0,1]$，使用 OLS 构造线性预测：\n",
    "$$b(\\textbf{x}) = \\textbf{w}^\\text{T} \\textbf{x} \\in \\mathbb{R}$$\n",
    "\n",
    "为了将所得结果转换为 [0,1] 区间内的概率，逻辑回归使用下列函数进行转换： \n",
    "$$\\sigma(z) = \\frac{1}{1 + \\exp^{-z}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逻辑回归预测一个样本分配为「+」分类的概率（假定已知模型的特征和权重），这一预测过程是通过对权重向量和特征向量的线性组合进行 sigmoid 变换完成的，公式如下：\n",
    "$$ p_+(\\textbf{x}_\\text{i}) = P\\left(y_i = 1 \\mid \\textbf{x}_\\text{i}, \\textbf{w}\\right) = \\sigma(\\textbf{w}^\\text{T}\\textbf{x}_\\text{i}). $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 20.1.1 from E:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip (python 3.8)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip3 -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12526dee0>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigma(z):\n",
    "    return 1. /(1+ np.exp(-z))\n",
    "\n",
    "xx = np.linspace(-10,10,1000)\n",
    "plt.plot(xx,[sigma(x) for x in xx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 逻辑回归的L2 正则化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逻辑回归的 L2 正则化和岭回归的情况基本一样。代替 $\\mathcal{L_{\\log}} (\\textbf X, \\textbf{y}, \\textbf{w})$，只用最小化下式：\n",
    "$$ \\mathcal{J}(\\textbf X, \\textbf{y}, \\textbf{w}) = \\mathcal{L_{\\log}} (\\textbf X, \\textbf{y}, \\textbf{w}) + \\lambda |\\textbf{w}|^2$$\n",
    "\n",
    "在逻辑回归中，通常使用正则化系数的倒数 $C = \\frac{1}{\\lambda}$：\n",
    "$$ \\widehat{\\textbf w}  = \\arg \\min_{\\textbf{w}} \\mathcal{J}(\\textbf X, \\textbf{y}, \\textbf{w}) =  \\arg \\min_{\\textbf{w}}\\ (C\\sum_{i=1}^{\\ell} \\log (1 + \\exp^{-y_i\\textbf{w}^\\text{T}\\textbf{x}_\\text{i}})+ |\\textbf{w}|^2)$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 逻辑回归的正则化示例 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score,StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 118 entries, 0 to 117\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   test1     118 non-null    float64\n",
      " 1   test2     118 non-null    float64\n",
      " 2   released  118 non-null    int64  \n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 2.9 KB\n"
     ]
    }
   ],
   "source": [
    "# 读取数据集，\n",
    "data = pd.read_csv('./dataset/microchip_tests.txt',header=None,\n",
    "                  names=('test1','test2','released')\n",
    "                  )\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test1</th>\n",
       "      <th>test2</th>\n",
       "      <th>released</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.051267</td>\n",
       "      <td>0.69956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.092742</td>\n",
       "      <td>0.68494</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.213710</td>\n",
       "      <td>0.69225</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.375000</td>\n",
       "      <td>0.50219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.513250</td>\n",
       "      <td>0.46564</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      test1    test2  released\n",
       "0  0.051267  0.69956         1\n",
       "1 -0.092742  0.68494         1\n",
       "2 -0.213710  0.69225         1\n",
       "3 -0.375000  0.50219         1\n",
       "4 -0.513250  0.46564         1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分离训练集 和目标分类标签\n",
    "X = data[['test1','test2']].values\n",
    "y = data['released'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2bd8100bfa0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制数据\n",
    "plt.scatter(X[y==1,0], X[y==1,1] , c='blue' , label='Released')\n",
    "plt.scatter(X[y==0,0], X[y==0,1], c='orange', label='Faulty')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- x[:,n]表示在全部数组（维）中取第n个数据，直观来说，x[:,n]就是取所有集合的第n个数据\n",
    "- x[n,:]表示在n个数组（维）中取全部数据，直观来说，x[n,:]就是取第n集合的所有数据\n",
    "- x[:,m:n]，即取所有数据集的第m到n-1列数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.051267 , -0.092742 , -0.21371  , -0.375    , -0.51325  ,\n",
       "       -0.52477  , -0.39804  , -0.30588  ,  0.016705 ,  0.13191  ,\n",
       "        0.38537  ,  0.52938  ,  0.63882  ,  0.73675  ,  0.54666  ,\n",
       "        0.322    ,  0.16647  , -0.046659 , -0.17339  , -0.47869  ,\n",
       "       -0.60541  , -0.62846  , -0.59389  , -0.42108  , -0.11578  ,\n",
       "        0.20104  ,  0.46601  ,  0.67339  , -0.13882  , -0.29435  ,\n",
       "       -0.26555  , -0.16187  , -0.17339  , -0.28283  , -0.36348  ,\n",
       "       -0.30012  , -0.23675  , -0.06394  ,  0.062788 ,  0.22984  ,\n",
       "        0.2932   ,  0.48329  ,  0.64459  ,  0.46025  ,  0.6273   ,\n",
       "        0.57546  ,  0.72523  ,  0.22408  ,  0.44297  ,  0.322    ,\n",
       "        0.13767  , -0.0063364, -0.092742 , -0.20795  , -0.20795  ,\n",
       "       -0.43836  , -0.21947  , -0.13882  ,  0.18376  ,  0.22408  ,\n",
       "        0.29896  ,  0.50634  ,  0.61578  ,  0.60426  ,  0.76555  ,\n",
       "        0.92684  ,  0.82316  ,  0.96141  ,  0.93836  ,  0.86348  ,\n",
       "        0.89804  ,  0.85196  ,  0.82892  ,  0.79435  ,  0.59274  ,\n",
       "        0.51786  ,  0.46601  ,  0.35081  ,  0.28744  ,  0.085829 ,\n",
       "        0.14919  , -0.13306  , -0.40956  , -0.39228  , -0.74366  ,\n",
       "       -0.69758  , -0.75518  , -0.69758  , -0.4038   , -0.38076  ,\n",
       "       -0.50749  , -0.54781  ,  0.10311  ,  0.057028 , -0.10426  ,\n",
       "       -0.081221 ,  0.28744  ,  0.39689  ,  0.63882  ,  0.82316  ,\n",
       "        0.67339  ,  1.0709   , -0.046659 , -0.23675  , -0.15035  ,\n",
       "       -0.49021  , -0.46717  , -0.28859  , -0.61118  , -0.66302  ,\n",
       "       -0.59965  , -0.72638  , -0.83007  , -0.72062  , -0.59389  ,\n",
       "       -0.48445  , -0.0063364,  0.63265  ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个函数来显示分类器的 分界线\n",
    "def plot_boundary(clf,X,y, grid_step=0.1, ploy_featurizer=None):\n",
    "    x_min ,x_max = X[:,0].min() - .1, X[:,0].max() +.1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
